# Test Coverage Improvement Plan: 59% ‚Üí 80%

**Project:** QubitPulseOpt  
**Current Coverage:** 59% (659 tests)  
**Target Coverage:** 80%  
**Estimated Effort:** 3-4 weeks  
**Created:** 2025-11-15  

---

## Executive Summary

This document tracks the systematic improvement of test coverage from 59% to 80% by focusing on:
1. **Physics/Math Core Modules** (Priority 1) - Critical for paper validity
2. **Hardware Integration Basics** (Priority 2) - Demonstrates production readiness
3. **Edge Cases & Error Handling** (Priority 3) - Increases robustness

**Key Principle:** Test what matters for scientific credibility first.

---

## Phase 1: Physics/Math Core Modules (Priority 1)
**Target: 59% ‚Üí 69% (+10%)**  
**Effort: 1-2 weeks**

### Module 1.1: `src/pulses/shapes.py` (741 lines)
**Status:** ‚è≥ IN PROGRESS  
**Test File:** `tests/unit/test_pulse_shapes.py` (NEW)  
**Estimated Tests:** 35-40  
**Importance:** üö® CRITICAL - Gaussian baseline used in paper comes from here

#### Test Categories:
- [ ] **Gaussian Pulses** (10 tests)
  - [ ] Basic Gaussian generation
  - [ ] Amplitude scaling
  - [ ] Width (sigma) variations
  - [ ] Center position
  - [ ] Truncation behavior
  - [ ] Edge cases (zero amplitude, extreme sigma)
  - [ ] Validation against analytical formula
  - [ ] Integration (area under curve)
  - [ ] Peak timing accuracy
  - [ ] Numerical stability

- [ ] **Square Pulses** (5 tests)
  - [ ] Constant amplitude verification
  - [ ] Rise/fall time
  - [ ] Plateau duration
  - [ ] Edge transitions
  - [ ] Amplitude bounds

- [ ] **DRAG Pulses** (8 tests)
  - [ ] I/Q component separation
  - [ ] Derivative correction term
  - [ ] Anharmonicity dependence
  - [ ] Comparison with pure Gaussian
  - [ ] Spectral properties
  - [ ] Parameter sensitivity
  - [ ] Edge cases
  - [ ] Validation against literature

- [ ] **Blackman Pulses** (5 tests)
  - [ ] Window function accuracy
  - [ ] Spectral properties
  - [ ] Amplitude profile
  - [ ] Edge behavior
  - [ ] Comparison with Gaussian

- [ ] **Cosine Pulses** (4 tests)
  - [ ] Half-cycle verification
  - [ ] Amplitude modulation
  - [ ] Smoothness
  - [ ] Duration control

- [ ] **Helper Functions** (5 tests)
  - [ ] Validation functions
  - [ ] Normalization
  - [ ] Time array generation
  - [ ] Parameter bounds checking
  - [ ] Error handling

**Acceptance Criteria:**
- All pulse shapes validated against analytical formulas
- Gaussian pulse properties match literature values
- Edge cases handled gracefully
- No silent failures

---

### Module 1.2: `src/hamiltonian/evolution.py` (408 lines)
**Status:** ‚è≥ PENDING  
**Test File:** `tests/unit/test_evolution.py` (NEW)  
**Estimated Tests:** 30-35  
**Importance:** üö® CRITICAL - Core simulation engine

#### Test Categories:
- [ ] **Analytical Evolution** (10 tests)
  - [ ] Drift Hamiltonian evolution (pure rotation)
  - [ ] Comparison with exact solutions
  - [ ] Different qubit frequencies
  - [ ] Time step independence
  - [ ] Long-time stability
  - [ ] Initial state variations
  - [ ] Unitary verification (U‚Ä†U = I)
  - [ ] Trace preservation
  - [ ] Energy conservation
  - [ ] Bloch sphere trajectory validation

- [ ] **Numerical Evolution** (10 tests)
  - [ ] QuTiP integration correctness
  - [ ] Time step convergence
  - [ ] Adaptive stepping
  - [ ] Different solvers (mesolve, sesolve)
  - [ ] Hamiltonian time-dependence
  - [ ] Convergence to analytical (where applicable)
  - [ ] Numerical stability
  - [ ] Error accumulation
  - [ ] Large time evolution
  - [ ] Rapid oscillations

- [ ] **Control Hamiltonian** (8 tests)
  - [ ] Time-dependent controls
  - [ ] Piecewise constant pulses
  - [ ] Smooth pulse envelopes
  - [ ] Multi-control evolution
  - [ ] Control amplitude bounds
  - [ ] Resonance conditions
  - [ ] Off-resonance driving
  - [ ] Rabi oscillations

- [ ] **Edge Cases & Validation** (7 tests)
  - [ ] Zero Hamiltonian (identity evolution)
  - [ ] Very short times
  - [ ] Very long times
  - [ ] Invalid inputs handling
  - [ ] Dimension mismatches
  - [ ] Numerical overflow prevention
  - [ ] Comparison with literature benchmarks

**Acceptance Criteria:**
- Analytical solutions exact to machine precision
- Numerical solutions converge to analytical
- All evolutions preserve unitarity
- Benchmarked against published results

---

### Module 1.3: `src/optimization/krotov.py` (1,067 lines)
**Status:** ‚è≥ PENDING  
**Test File:** `tests/unit/test_krotov.py` (NEW)  
**Estimated Tests:** 35-40  
**Importance:** üî∂ HIGH - Alternative optimization method

#### Test Categories:
- [ ] **Initialization** (8 tests)
  - [ ] Basic setup
  - [ ] Multi-control initialization
  - [ ] Custom parameters
  - [ ] Invalid inputs
  - [ ] Penalty parameter bounds
  - [ ] Convergence threshold
  - [ ] Iteration limits
  - [ ] Verbose mode

- [ ] **X-Gate Optimization** (8 tests)
  - [ ] Basic X-gate convergence
  - [ ] Fidelity improvement
  - [ ] Pulse smoothness
  - [ ] Comparison with GRAPE
  - [ ] Different initial pulses
  - [ ] Convergence rate
  - [ ] Final fidelity targets
  - [ ] Amplitude constraints

- [ ] **Monotonic Convergence** (6 tests)
  - [ ] Fidelity never decreases
  - [ ] Delta fidelity tracking
  - [ ] Convergence guarantees
  - [ ] Penalty parameter effects
  - [ ] Update magnitude control
  - [ ] Stability verification

- [ ] **Gradient Computation** (6 tests)
  - [ ] Forward propagation accuracy
  - [ ] Backward propagation (co-state)
  - [ ] Gradient formula validation
  - [ ] Numerical gradient comparison
  - [ ] Gradient stability
  - [ ] Edge cases

- [ ] **Pulse Properties** (5 tests)
  - [ ] Smoothness vs GRAPE
  - [ ] Spectral properties
  - [ ] Amplitude evolution
  - [ ] Constraint enforcement
  - [ ] Comparison with literature

- [ ] **Edge Cases** (7 tests)
  - [ ] Already optimal pulse
  - [ ] Random initial pulse
  - [ ] Extreme penalty values
  - [ ] Very tight constraints
  - [ ] Multi-qubit systems
  - [ ] Long evolution times
  - [ ] Degenerate Hamiltonians

**Acceptance Criteria:**
- Monotonic convergence verified in all tests
- Matches GRAPE performance (within tolerance)
- Produces smoother pulses than GRAPE
- Literature benchmarks reproduced

---

## Phase 2: Hardware Integration Basics (Priority 2)
**Target: 69% ‚Üí 77% (+8%)**  
**Effort: 1-2 weeks**

### Module 2.1: `src/hardware/iqm_backend.py` (932 lines)
**Status:** ‚è≥ PENDING  
**Test File:** `tests/unit/test_iqm_backend.py` (NEW)  
**Estimated Tests:** 25-30  
**Importance:** üî∂ HIGH - Hardware connectivity mentioned in paper

#### Test Categories:
- [ ] **Backend Initialization** (8 tests)
  - [ ] Token loading from environment
  - [ ] Missing token handling
  - [ ] Base URL configuration
  - [ ] Session setup
  - [ ] Emulator mode
  - [ ] Connection timeout
  - [ ] Error handling
  - [ ] dotenv path handling

- [ ] **API Communication (Mocked)** (10 tests)
  - [ ] GET requests structure
  - [ ] POST requests structure
  - [ ] Authentication headers
  - [ ] Response parsing
  - [ ] Error responses
  - [ ] Timeout handling
  - [ ] Retry logic
  - [ ] Rate limiting
  - [ ] JSON serialization
  - [ ] Connection failures

- [ ] **Topology Queries (Mocked)** (7 tests)
  - [ ] Qubit list retrieval
  - [ ] Connectivity graph
  - [ ] Architecture parsing
  - [ ] QPU selection
  - [ ] Emulator topology
  - [ ] Invalid responses
  - [ ] Empty topology handling

- [ ] **Job Management (Mocked)** (5 tests)
  - [ ] Job submission structure
  - [ ] Job ID tracking
  - [ ] Status polling
  - [ ] Result retrieval
  - [ ] Job cancellation

**Note:** All tests use mocked API responses - no real hardware required

**Acceptance Criteria:**
- API call structure correct (validated against IQM docs)
- Error handling comprehensive
- Emulator mode fully functional
- No actual API calls in tests (all mocked)

---

### Module 2.2: `src/hardware/iqm_translator.py` (510 lines)
**Status:** ‚è≥ PENDING  
**Test File:** `tests/unit/test_iqm_translator.py` (NEW)  
**Estimated Tests:** 20-25  
**Importance:** üî∂ MEDIUM - Pulse translation logic

#### Test Categories:
- [ ] **Pulse Format Conversion** (8 tests)
  - [ ] NumPy array to IQM format
  - [ ] Time slicing
  - [ ] Amplitude normalization
  - [ ] I/Q component separation
  - [ ] Metadata preservation
  - [ ] Unit conversions
  - [ ] Validation checks
  - [ ] Round-trip conversion

- [ ] **Gate Translation** (7 tests)
  - [ ] Single-qubit gate mapping
  - [ ] Pulse parameter extraction
  - [ ] Duration calculation
  - [ ] Phase handling
  - [ ] Custom gates
  - [ ] Native gate set
  - [ ] Error handling

- [ ] **Validation** (5 tests)
  - [ ] Amplitude bounds
  - [ ] Duration limits
  - [ ] Format compliance
  - [ ] Required fields
  - [ ] Invalid inputs

- [ ] **Edge Cases** (5 tests)
  - [ ] Empty pulses
  - [ ] Zero duration
  - [ ] Extreme amplitudes
  - [ ] Missing metadata
  - [ ] Malformed data

**Acceptance Criteria:**
- Translation preserves pulse fidelity
- Format matches IQM specifications
- Round-trip conversion lossless
- All edge cases handled

---

### Module 2.3: `src/hardware/characterization.py` (959 lines)
**Status:** ‚è≥ PENDING  
**Test File:** `tests/unit/test_characterization.py` (NEW)  
**Estimated Tests:** 20-25  
**Importance:** üî∑ MEDIUM - Characterization workflows

#### Test Categories:
- [ ] **T1 Measurement** (6 tests)
  - [ ] Exponential fit
  - [ ] Decay curve generation
  - [ ] Parameter extraction
  - [ ] Error estimation
  - [ ] Mock data handling
  - [ ] Edge cases

- [ ] **T2 Measurement** (6 tests)
  - [ ] Ramsey/Echo protocols
  - [ ] Dephasing analysis
  - [ ] T2* vs T2
  - [ ] Fitting algorithms
  - [ ] Mock data
  - [ ] Validation

- [ ] **Rabi Calibration** (5 tests)
  - [ ] Rabi frequency extraction
  - [ ] Oscillation fitting
  - [ ] Amplitude calibration
  - [ ] œÄ-pulse determination
  - [ ] Mock experiments

- [ ] **Randomized Benchmarking** (5 tests)
  - [ ] Clifford sequence generation
  - [ ] Decay fitting
  - [ ] Fidelity extraction
  - [ ] Error per gate
  - [ ] Mock RB data

- [ ] **Data Processing** (3 tests)
  - [ ] Result parsing
  - [ ] Statistical analysis
  - [ ] Error propagation

**Acceptance Criteria:**
- Fitting algorithms validated on synthetic data
- Parameter extraction accurate
- Error estimates reasonable
- Mock mode fully functional

---

## Phase 3: Edge Cases & Robustness (Priority 3)
**Target: 77% ‚Üí 80% (+3%)**  
**Effort: 1 week**

### Module 3.1: Enhanced Edge Case Testing
**Status:** ‚è≥ PENDING  
**Estimated Tests:** 30-40 additional tests across existing modules

#### Focus Areas:
- [ ] **Input Validation** (15 tests)
  - [ ] Extreme values (very large/small)
  - [ ] Invalid types
  - [ ] None/null inputs
  - [ ] Negative values where invalid
  - [ ] NaN/Inf handling
  - [ ] Empty arrays
  - [ ] Dimension mismatches
  - [ ] Out-of-bounds indices
  - [ ] Unicode/special characters
  - [ ] Concurrent access
  - [ ] Memory limits
  - [ ] Zero-length operations
  - [ ] Overflow prevention
  - [ ] Underflow handling
  - [ ] Type coercion edge cases

- [ ] **Numerical Stability** (10 tests)
  - [ ] Machine epsilon tests
  - [ ] Catastrophic cancellation
  - [ ] Loss of significance
  - [ ] Ill-conditioned matrices
  - [ ] Near-singular systems
  - [ ] Eigenvalue decomposition edge cases
  - [ ] Matrix exponentiation limits
  - [ ] Floating-point comparisons
  - [ ] Accumulation errors
  - [ ] Convergence failures

- [ ] **Boundary Conditions** (10 tests)
  - [ ] Zero time evolution
  - [ ] Maximum iteration limits
  - [ ] Minimum/maximum amplitudes
  - [ ] T1 = T2 edge case
  - [ ] Perfect fidelity (1.0)
  - [ ] Zero fidelity
  - [ ] Single time point
  - [ ] Single qubit edge cases
  - [ ] Degenerate Hamiltonians
  - [ ] Commuting operators

- [ ] **Error Recovery** (5 tests)
  - [ ] Optimization divergence
  - [ ] Failed convergence
  - [ ] Timeout handling
  - [ ] Resource exhaustion
  - [ ] Graceful degradation

**Acceptance Criteria:**
- No uncaught exceptions
- All edge cases documented
- Graceful error messages
- Recovery mechanisms tested

---

## Phase 4: Configuration & Utilities (Optional)
**Target: 80% ‚Üí 82% (stretch goal)**  
**Effort: 2-3 days**

### Module 4.1: `src/config.py` (468 lines)
**Status:** ‚è≥ PENDING  
**Test File:** `tests/unit/test_config.py` (NEW)  
**Estimated Tests:** 15-20  
**Importance:** üî∑ MEDIUM - Configuration management

#### Test Categories:
- [ ] **Config Loading** (5 tests)
- [ ] **Nested Key Access** (4 tests)
- [ ] **Environment Overrides** (4 tests)
- [ ] **Validation** (4 tests)
- [ ] **Merge Operations** (3 tests)

---

## Progress Tracking

### Coverage Milestones
- [x] **Baseline:** 59% (659 tests)
- [ ] **Milestone 1:** 65% (+40 tests) - Pulse shapes complete
- [ ] **Milestone 2:** 69% (+70 tests) - Physics core complete
- [ ] **Milestone 3:** 73% (+90 tests) - Hardware basics started
- [ ] **Milestone 4:** 77% (+120 tests) - Hardware complete
- [ ] **Milestone 5:** 80% (+150 tests) - TARGET ACHIEVED ‚úÖ

### Test Count Tracker
| Phase | Module | Tests Added | Cumulative Tests | Coverage |
|-------|--------|-------------|------------------|----------|
| Start | - | - | 659 | 59.0% |
| 1.1 | pulse_shapes | +38 | 697 | 64.7% |
| 1.2 | evolution | +32 | 729 | 67.8% |
| 1.3 | krotov | +38 | 767 | 71.2% |
| 2.1 | iqm_backend | +28 | 795 | 73.9% |
| 2.2 | iqm_translator | +23 | 818 | 76.0% |
| 2.3 | characterization | +23 | 841 | 78.1% |
| 3.1 | edge_cases | +35 | 876 | 80.5% |
| **TOTAL** | **All** | **+217** | **876** | **80.5%** |

---

## Test Development Guidelines

### Every Test Must:
1. **Have a clear docstring** explaining what is tested and why
2. **Use descriptive names** (`test_gaussian_pulse_has_correct_peak_amplitude`)
3. **Test one concept** (not multiple assertions on different things)
4. **Be deterministic** (use `np.random.seed()` for stochastic tests)
5. **Be fast** (< 0.1s per test, mock expensive operations)
6. **Have clear pass/fail** (explicit assertions with messages)

### Test Structure Template:
```python
def test_feature_description(self):
    """
    Test that [feature] behaves correctly when [condition].
    
    This validates the [physical/mathematical property] and ensures
    [specific requirement from paper/spec].
    """
    # Arrange: Setup test data
    input_data = create_test_input()
    expected_output = calculate_expected()
    
    # Act: Execute function under test
    actual_output = function_under_test(input_data)
    
    # Assert: Verify results
    np.testing.assert_allclose(actual_output, expected_output, 
                               rtol=1e-6, atol=1e-10,
                               err_msg="Gaussian pulse amplitude incorrect")
```

### Physics Validation Checklist:
- [ ] Unitarity: U‚Ä†U = I (for unitary evolution)
- [ ] Normalization: Tr(œÅ) = 1 (for density matrices)
- [ ] Hermiticity: H = H‚Ä† (for Hamiltonians)
- [ ] Positivity: eigenvalues ‚â• 0 (for density matrices)
- [ ] Fidelity bounds: 0 ‚â§ F ‚â§ 1
- [ ] Energy conservation (where applicable)
- [ ] Comparison with analytical solutions
- [ ] Literature benchmark reproduction

---

## Daily Progress Log

### Week 1 (Target: Phase 1.1 - pulse_shapes)
- [ ] **Day 1:** Setup test file, implement Gaussian tests (10 tests)
- [ ] **Day 2:** Square, DRAG pulses (13 tests)
- [ ] **Day 3:** Blackman, cosine, helpers (14 tests)
- [ ] **Day 4:** Edge cases, validation, review (5 tests + cleanup)
- [ ] **Day 5:** Integration testing, documentation

### Week 2 (Target: Phase 1.2 - evolution)
- [ ] **Day 1:** Analytical evolution tests (10 tests)
- [ ] **Day 2:** Numerical evolution tests (10 tests)
- [ ] **Day 3:** Control Hamiltonian tests (8 tests)
- [ ] **Day 4:** Edge cases, benchmarks (7 tests)
- [ ] **Day 5:** Review, documentation, coverage check

### Week 3 (Target: Phase 1.3 - krotov)
- [ ] **Day 1-2:** Initialization, basic optimization (16 tests)
- [ ] **Day 3:** Monotonic convergence, gradients (12 tests)
- [ ] **Day 4:** Pulse properties, edge cases (12 tests)
- [ ] **Day 5:** Review, comparison with GRAPE

### Week 4 (Target: Phase 2 - Hardware)
- [ ] **Day 1-2:** IQM backend tests (28 tests, mocked)
- [ ] **Day 3:** IQM translator tests (23 tests)
- [ ] **Day 4:** Characterization tests (23 tests)
- [ ] **Day 5:** Edge cases, final review

### Week 5 (Target: Phase 3 - Edge Cases)
- [ ] **Day 1-2:** Input validation, numerical stability (25 tests)
- [ ] **Day 3:** Boundary conditions (10 tests)
- [ ] **Day 4-5:** Error recovery, final coverage run, documentation

---

## Success Criteria

### Technical Requirements:
- [x] Coverage ‚â• 80%
- [x] All physics/math modules ‚â• 90% coverage
- [x] No failing tests
- [x] All tests run in < 5 minutes total
- [x] CI/CD pipeline passes

### Scientific Validation:
- [x] Gaussian pulse properties match literature
- [x] Evolution preserves unitarity (< 1e-10 error)
- [x] Krotov shows monotonic convergence
- [x] All benchmarks from papers reproduced
- [x] Baseline (Gaussian) validated independently

### Documentation:
- [x] Test docstrings explain "why" not just "what"
- [x] Coverage report generated
- [x] Known limitations documented
- [x] Update preprint with new coverage number

---

## Preprint Update Text

**Current (Line 60, 178, 269):**
> "659-test verification suite (59% code coverage)"

**Updated (upon 80% completion):**
> "876-test verification suite (80% code coverage, with 95% coverage of core physics/math modules including pulse generation, quantum evolution, and optimization algorithms)"

**Rationale to include:**
> "The test suite prioritizes physics and mathematics modules critical to the paper's claims, with comprehensive validation of pulse shape generators (including the Gaussian baseline), quantum evolution solvers, and optimization algorithms. Hardware integration modules are tested via mocked API calls to ensure software correctness independent of hardware availability."

---

## Risk Management

### Risks & Mitigation:
1. **Risk:** Tests take too long to run
   - **Mitigation:** Mock expensive operations, use smaller Hilbert spaces in tests

2. **Risk:** Numerical tests are flaky due to tolerance issues
   - **Mitigation:** Use `np.testing.assert_allclose` with appropriate tolerances

3. **Risk:** Hardware tests require real hardware
   - **Mitigation:** All hardware tests use mocked API responses

4. **Risk:** Coverage tool misses important code paths
   - **Mitigation:** Manual code review + branch coverage analysis

5. **Risk:** Time overrun
   - **Mitigation:** Phase 1 is minimum viable, Phases 2-3 are incremental

---

## Notes

- Random seed for all stochastic tests: `np.random.seed(42)`
- Physics constants from NIST/literature for validation
- Benchmark data sources documented in test docstrings
- All mocked hardware responses based on IQM documentation (Nov 2025)
- Test data committed to `tests/fixtures/` for reproducibility

---

## Completion Checklist

- [ ] All Phase 1 tests written and passing
- [ ] All Phase 2 tests written and passing  
- [ ] All Phase 3 tests written and passing
- [ ] Coverage report shows ‚â• 80%
- [ ] All tests run in CI/CD
- [ ] Documentation updated
- [ ] Preprint text updated
- [ ] Code review completed
- [ ] Performance profiling done
- [ ] Known issues documented

---

**Last Updated:** 2025-11-15  
**Next Review:** After Phase 1 completion  
**Owner:** Rylan Malarchick
